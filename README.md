# Hyperspectral_img_stitching

This is the code related to our paper 'Evaluation of cotton emergence using UAV-based narrow-band spectral imagery with customized image alignment and stitching algorithms' authored by Aijing Feng, Jianfeng Zhou, Earl Vories and Kenneth Sudduth.
In this paper, we developed a methods for unmanned aerial vehicle (UAV)-based pushbroom narrow-band spectral image alignment and stitching.

*If this help your research and projects, please cite us~*

Feng, A., Zhou, J., Vories, E., & Sudduth, K. A. (2020). Evaluation of cotton emergence using UAV-based narrow-band spectral imagery with customized image alignment and stitching algorithms. Remote Sensing, 12(11), 1764. 

## How a pushbroom hyperspectral image looks like?
An image framecollected by the pushbroom hyperspectral camera was an 8-bit grey scale image. One raw image collected in the test field shows that each image frame includes 824 × 2048 effective pixels. The 824 pixels in the vertical direction are generated by the 103 bands of the camera, with eight pixels per band, i.e. 103 × 8 = 824 pixels. There are 2048 pixels for each spectral band forming a so-called spectral line in the horizontal direction, which covered 16 meters on the ground when acquired at 50 m AGL.
![alt text](https://github.com/AJFeng/Hyperspectral_img_stitching/blob/main/figures/pushbroom.png)

## Workflow of the spectral band stitching process.
To generate a panorama of the target field in each spectral band, an algorithm was developed to process the raw images. 

The processing procedure included (1) feature detection and matching, (2) removal of false matches, (3) calculation of a geometric transformation matrix, and (4) development of spectral band stitching images. Raw image features were detected to stitch the successive images. Then, the matching features between every two successive raw images were used to calculate a transformation matrix M. Each raw image consisted of 103 bands, each 8 pixels wide. To generate a panorama image for each band, the 8-pixel strips of each band were segmented from all the raw images, and stitched using the same transformation matrix M calculated from the raw image frames. In the end, spectral cubes containing 103 bands in the Z-axis were generated. These cubes had the same 2048-pixel width as the raw images in the X-axis, and the Y-axis corresponding with the length of the image scanning paths of the two scanning directions. The final spectral cubes were the panorama images collected for each UAV flight path.
![alt text](https://github.com/AJFeng/Hyperspectral_img_stitching/blob/main/figures/Workflow.png)

(a) Soil ECa map marked with flight paths and ground reference points. The triangles and rectangles have the same meaning as in Figure 2. (b) Spectral reflectance of the cotton seedlings and soil at the selected locations #4, #5 and #6 in the research field as shown in (a). (c) An RGB image taken at 15 m AGL in location #1 of (a) showing soil color differences due to different soil texture and water content.
![alt text](https://github.com/AJFeng/Hyperspectral_img_stitching/blob/main/figures/Soil_crop_reference.png)
